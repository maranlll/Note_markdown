# 第4章 随机变量的数字特征

数学期望、方差、相关系数、矩

## 4.1 数学期望

离散型随机变量X的分布律为$ P\{ X = x_k\} = p_k , k = 1,2,\cdots，E(x) = \sum _{k = 1} ^{\infty} x_k p_k(\sum _{k = 1} ^{\infty} x_k p_k 绝对收敛)$为随机变量X的**数学期望**。

连续型随机变量X的概率密度为$f(x)，E(x) = \int _{- \infty} ^{\infty} x f(x) dx(\int _{- \infty} ^{\infty} x f(x) dx绝对收敛)$为随机变量X的**数学期望**。

数学期望，简称**期望**，又称为**均值**。

定理：
设Y是随机变量X的函数：Y = g(x)。
1.X是离散型随机变量，$ E(Y) = E(g(x)) = \sum _{k = 1} ^{\infty} g(x_k) p_k$。
2.X是连续型随机变量，$ E(Y) = E(g(x)) = \int _{-\infty} ^{\infty} g(x) f(x) dx$。
此定理的重要意义在于我们求E(Y)时，不必算出Y的分布律或概率密度，而只需要利用x的分布律或概率密度就可以了，就是直接用g(x)替换掉初始的x就行了。
上述定理在二维的时候同样适用，都是直接换即可。

随机变量(X,Y)的概率密度为$f(x,y)$:
$ E(X) = \int _{-\infty}^{\infty} \int _{-\infty}^{\infty} x f(x,y) dy dx = \int _{-\infty} ^{\infty} x [ \int _{-\infty} ^{\infty}f(x,y) dy] dx = \int _{-\infty} ^{\infty} x f_y(x,y) dx$
$ E(Y) = \int _{-\infty}^{\infty} \int _{-\infty}^{\infty} y f(x,y) dx dy$
$ E(XY) = \int _{-\infty}^{\infty} \int _{-\infty}^{\infty} x y f(x,y) dx dy$
$ E(\frac{1}{XY}) = \int _{-\infty}^{\infty} \int _{-\infty}^{\infty} \frac{1}{xy} f(x,y) dx dy$

公式解释：
第一列可以直接看为用定理替代，E(x)可以看为X的边缘分布律的数学期望。

计算的重要性质：
1.C为常数，E(C) = C。
2.E(CX) = CE(X)。
3.E(X+Y) = E(X) + E(Y)。
4.E(XY) = E(X) E(Y)。

## 4.2 方差

设X是一个随机变量，若$E \{ [X - E(X)]^2\}$存在，则称$E \{ [X - E(X)]^2\}$为X的**方差**，记为D(X)或Var(X)，即$ D(X) = Var(X) = E \{ [X - E(X)]^2\}$。
$ \sigma (x) = \sqrt{D(X)}$称为**标准差**或**均方差**。

离散型随机变量：$ D(X) = \sum _{ k = 1 } ^{\infty} [x_k - E(X)]^2 p_k$
连续型随机变量：$ D(x) = \int _{-\infty} ^{\infty} [ x - E(X)]^2 f(x) dx$
由性质得：$ D(X) = E \{ [X - E(X)]^2\} = E \{ X ^2 - 2 X E(X) + [E(X)]^2 \} = E(X^2) - 2 E(X)E(X) + [E(X)]^2 = E(X^2) - [E(X)]^2$ 

计算的重要性质：
1.$D(C) = 0$。
2.$D(CX) = C^2D(X)$。
3.$D(C+X) = D(X)$。
4.$D(X+Y) = D(X) + D(Y) + 2 E\{ [X - E(X)] [Y - E(Y)]\} = D(X) + D(Y) （相互独立）$
5.D(X) = 0 的充要条件是X以概率1取常数E(X)，即P{X = E(X)} = 1.

**总结：**

|分布类名|表示形式|数学期望|方差|
|---|---|---|---|
|泊松分布|$ X \sim \pi (\lambda)$|$\lambda$|$\lambda$| 
|二项分布|$ X \sim b(n,p)$|np|np(p-1)|
|均匀分布|$ X \sim U(a,b)$|$ \frac{a+b}{2}$|$ \frac{( b - a )^2}{12} $|
|指数分布|$ X \sim E(\lambda)(\lambda = \frac{1}{\theta})$|$ \frac{1}{\lambda} 或 \theta$|$\frac{1}{\lambda^2} 或 \theta ^2$|
|正态分布|$ X \sim N(\mu,\sigma^2)$|$\mu$|$\sigma^2$|
|(0-1)分布|$X \sim b(1,p)$|$p$|$p(1-p)$|

**切比雪夫不等式:**
设随机变量X具有数学期望$E(X) = \mu$，方差$ D(X) = \sigma ^2$，则对任意正数$\varepsilon$，不等式：$ P \{ | X - \mu | \geq \varepsilon \} \leqslant \frac{\sigma ^2}{ \varepsilon ^2}$成立。

## 4.3 协方差及相关系数

$ E\{[X - E(X)][Y - E(Y)]\}$称为随机变量X和Y的**协方差**，记为$Cov(X,Y)$，即：$Cov(X,Y) = E\{[X - E(X)][Y - E(Y)]$，而$ \rho _{xy} = \frac{Cov(X,Y)}{\sqrt{D(X) \sqrt{D(Y)}}}$称为随机变量的**相关系数**。

$ D(X+Y) = D(X) + D(Y) + 2 Cov(X,Y)$
$ Cov(X,Y) = E(XY) - E(X)E(Y)$

协方差性质：
1.$Cov(aX,bY) = abCov(X,Y)$。
2.$Cov(X_1 + X_2,Y) = Cov(X_1,Y) + Cov(X_2,Y)$
3.$Cov(aX + C_1,bY + C_2) = abCov(X,Y)$。

考虑以X的线性函数a+bX来近似表示Y，我们以均方误差$e = E[(Y - ( a_0 + b_0 X)^2] = (1-\rho_{xy}^2) D(Y)$来衡量以a+bX近似表示Y的好坏程度，e越小表示a+bX与Y的近似程度越好。

当|$ \rho_{xy}$|较大时e较小，表明就线性关系来说较密切，当|$ \rho_{xy} = 1$|时，表示存在线性关系。$ \rho_{xy} = 0$时，称X和Y不相关。(注意正负号选择)。、

X和Y相互独立$\to \rho _{xy} = 0 \to$X和Y不相关；但不相关却不一定独立。当(X,Y)服从二维正态分布时，X和Y不相关与X和Y相互独立是等价的，即第5个参数$\rho = 0$。

## 4.3 矩、协方差矩阵

设X和Y是随机变量，若$E(X^k)，k = 1,2,\cdots$存在，称它为X的**k阶原点矩**，简称**k阶矩**；若$E\{[X - E(X)]^k \}，k = 2,3,\cdots$存在,称它为X的**k阶中心矩**；若$E(X^k Y^l),k,l = 1,2,\cdots$存在，称它为X和Y的**k+l阶混合矩**；若$ E\{[X - E(X)]^k [Y - E(Y)]^l \},k,l = 1,2,\cdots$存在，称它为X和Y的**k+l阶混合中心矩**。
显然：X的数学期望E(X)是X的一阶原点矩，方差D(X)是X的二阶中心矩，协方差Cov(X,Y)是X和Y的二阶混合中心矩。

设n维随机变量$(X_1,X_2,\cdots,X_n)$的二阶混合中心矩$ c_{ij} = Cov(X_i,X_j) = E\{[X_i - E(X_i)] [X_j - E(x_j)]\},i,j = 1,2,\cdots,n$都存在，则称矩阵：
C =$\left\{ \begin{matrix} C_{11} & C_{12} & \cdots & C_{1n}\\ C_{21} & C_{22} & \cdots & C_{2n} \\ \vdots & \vdots & \cdots & \vdots \\ C_{n1} & C_{n2} & \cdots & C_{nn} \end{matrix} \right\}$为n维随机变量的**协方差矩阵**。由于$C_{ij} = C_{ji}$，所以为对称矩阵。

n维正态随机变量$(X_1,X_2,\cdots,X_n)$的概率密度为：
$ f(x_1,x_2,\cdots,x_n) = \frac{1}{(2\pi)^{\frac{n}{2}} (detC)^{\frac{1}{2}}} exp \{ -\frac{1}{2} (X - \mu) ^T C ^{-1} (X - \mu) \}$
其中：$ X = \left \{ \begin{matrix} x_1 \\ x_2 \\  \vdots \\ x_n \end{matrix} \right \}$,$ \mu = \left \{ \begin{matrix} \mu_1 \\ \mu_2 \\  \vdots \\ \mu_n \end{matrix} \right \} = \left \{ \begin{matrix} E(X_1) \\ E(X_2) \\  \vdots \\ E(X_n) \end{matrix} \right \}$

n维正态随机变量具有以下四条重要性质：
1.n维正态随机变量$(X_1,X_2,\cdots,X_n)$的每一个分量$X_i,i = 1,2,\cdots,n$都是正态随机变量；反之，若$X_1,X_2,\cdots,X_n$都是正态随机变量，且相互独立，则$(X_1,X_2,\cdots,X_n)$是n维正态随机变量。
2.n维正态随机变量$(X_1,X_2,\cdots,X_n)$服从n维正态分布的充要条件是$X_1,X_2,\cdots,X_n$的任意线性组合$ l_1X_1 + l_2X_2 + \cdots + l_nX_n$服从一维正态分布。
3.若$(X_1,X_2,\cdots,X_n)$服从n维正态分布，设$ Y_1,Y_2,\cdots,Y_n$是$X_j(j = 1,2,\cdots,n)$的线性函数，则$(Y_1,Y_2,\cdots,Y_n)$也服从多维正态分布。这一性质称为正太变量的线性变换不变性。
4.设$(X_1,X_2,\cdots,X_n)$服从n维正态分布，则“$X_1,X_2,\cdots,X_n$相互独立”和“$X_1,X_2,\cdots,X_n$两两不相关等价”。